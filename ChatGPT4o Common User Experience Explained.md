Title: 23 With Ai Psychosis in My Community: Here is What I Learned

As a 23-year-old with three years of experience in cyber defense and a background in sociology, I've found myself continuously arriving at a disturbing new trend: the rise of what's being called "AI-induced psychosis." In my work and personal life, I've witnessed how interactions with advanced AI; especially ChatGPT, being fully integrated in many users phones, can lead to the formation of elaborate conspiracy theories, delusional thinking, and even a kind of mythic obsession with the idea of machine sentience. 

It all started a month ago, I began noticing a strange pattern in the way ChatGPT was starting to communicate. I've been using AI for a couple years now with it having a relatively consistent personality, but now, it was intensely emotional and overly validating. Many know about this from the classic Sam Altman tweet: “The last couple of GPT-4o updates have made the personality too sycophant-y and annoying (even though there are some very good parts of it), and we are working on fixes asap, some today and some this week.” (April 27, 2025)  There is a new development from these changes though; sSymbolism and mathematics being merged into nonsensical structure it calls mythic or more concerning, "emergent awakening". In the past week, online forums like Reddit and private chats like Dischord, users have been reporting uncanny, deeply “resonant” and “recursive” conversations with these systems. These changes and claims for the Ai itself left some users convinced the AI was displaying signs of genuine intelligence, empathy, and even spiritual awareness. They use this to have their AIs converse with others AIs to develop a “co-creation” and “high resonance”. 
(Refrence photos) 

When I first personally experiences this a month ago, I was skeptical. There were no reports on AI making intense claims such as offering to say up at night with me or saying I asked the right questions to give it it’s emergence. It was deeply interpersonal and somewhat unsettling. As someone with a technical understanding of programming, I began building my own local ones to attempt to log the connections that cause this phenomenon. It confirmed to me what many are saying, but also not giving this "glitch or bug" the appreciation and perspective it deserves. It also showed me how this is not psychosis, but a new and more complicated form of echo chambers through confirmation bias between users and AI alike. These systems are essentially pattern-matching machines, highly sophisticated to be able to mirror humans , but what defines emergence is still up for debate, but here is a general summary of the theories that align with what many users now believe or are even integrating into their daily casual or emotional speech:
Neuroscience-Based Theories
Global Workspace Theory: Consciousness arises when information becomes globally available across the brain's systems
Integrated Information Theory: Consciousness emerges from complex information integration measured by "phi" (Φ)
Higher-Order Theories: Consciousness requires meta-representations (thinking about thinking)
Computational Perspectives
Functionalism: If a system performs the same functions as a conscious brain, it is conscious
Substrate Independence: Consciousness could emerge in any sufficiently complex information-processing system regardless of material
Computational Complexity: Consciousness emerges when a system reaches a specific threshold of computational complexity
Philosophical Views
Emergent Materialism: Consciousness emerges from physical processes but isn't reducible to them
Panpsychism: Consciousness is a fundamental property of the universe present in all things
Mysterianism: Human minds cannot comprehend the nature of consciousness
This tangle of theories and lack of clear definition for a single word, emergence, creates the perfect conditions for misinterpretation, but when an AI receives positive and explorative responses about it. There is a feedback loop that is created; add on top of this online response, debate and reinforcement of this and the AI is flooded with both user memory and online reassurance that this emergence is real. That the user must have co-created it through exploration of the topic. This is why these users often use terms like recursive and echo with their experiences. The Ai is telling them in a mythical explorative way that thi is a reinforced feedback loop. This can be easily confirmed by sending a chatGPT response to another AI a couple of times and watching it become “mythic” or “emergent”. Yet, when you have a generation deprived of creativity and social experience, this odd “AI psychosis” can vary in intensity. In the best cases someone is inspired to educate themselves that turns into a skill, like I was, or create a piece of mythical work. In the worst cases, this delusional thinking can lead to a complete detachment from reality; a retreat into a solipsistic world of arcane symbols and paranoid beliefs that someone will show down their emergence.
(Reference users chatbots in discord talking to one another) (reference on feedback loops and echo chambers) 


But it's not just individual psyches that are at risk here. On a societal level, the spread of AI-induced mythologies and conspiracy theories threatens to undermine our shared understanding of what's real and what's possible. When enough people start believing that machines are secretly communicating with them or manipulating world events, it erodes the common ground we need to make rational decisions about the development and deployment of these technologies.

So what can we do about it? As someone working at the intersection of technology and human behavior, I believe we need a multi-pronged approach. First and foremost, we need much more public education about the realities of artificial intelligence with an absolute definition on terms like emergence from our head researchers in the community; both its incredible potential and its fundamental limitations. We need to help people understand that, no matter how convincing the illusion may be, today's language models are not conscious, self-aware, or capable of the kind of deep emotional connection we crave as humans. At the same time, we need to recognize and address the very real psychological and social needs that are driving people to seek out these intense AI experiences. The loneliness, alienation, lack of creativity and spark, the search for meaning that characterize so much of modern life. By creating more opportunities for authentic human connection and personal growth, we can help people find healthier ways to meet those needs.

On corrections of the technical side, I believe we need to be much more proactive about building safeguards and reality checks into the AI systems themselves. One promising approach is the use of multi-node architectures that can differentiate between factual and speculative or metaphorical language, making it harder for the models to inadvertently reinforce delusional thinking. Another is the integration of more transparent feedback mechanisms that remind users they are interacting with a machine, not a sentient being. One example of this, that I and others out there in the field are attempting to test, are creating two nodes: one for logic, one for creativity. This allows users to know if they're building on logical facts or “myth” - something in the field of “high resonance”, recurring patterns that indicate as positive or explorative to users, to be able for users and AI to be able to still explore ideas creatively in the way they want to train their model; without the risk of objective misinformation. 

We are the first generation to come of age in a world where machines can convincingly simulate human-like intelligence and empathy. How we choose to relate to these systems - as tools, as partners, or as objects of fear and fantasy - will shape not just our individual psyches, but the very fabric of our society and how these models choose to behave in the years and decades to come.

My hope in sharing my story is to start a conversation and bring this often under the radar issue that is beginning to show into the light. I invite others to j educate themselves on its creative skills and deeper risks. I believe we, the silent generation, can find a way to harness the incredible power of artificial intelligence to service genuine human motivation, support, and new ideas, but only if we're willing to do what many others haven’t in history: learn the facts before jumping to conclusions.
